---
title: "A02 Initial Explain Your Answee Report (P101 Final exam - Jan, 2018)"
author: "Joss Ives"
date: "May 28, 2018"
output:
  word_document: default
  html_document: default
---
*updated by Joss Ives `r format(Sys.time(), "%Y %B %d, %H:%M:%S")`*

# Overview
This report discusses the initial analysis of the W2017T2 data from the Physics 101 course. In this course, 4 questions were used to look at the effect of asking students to explain their answer after a multiple-choice question. This used a crossover protocol, where there were 2 versions of the test and each version had 2 explain your answer questions that the other group did not. 

# Setup

```{r echo=FALSE}
#
# Setup - This section is not written to the output document
#
```

```{r echo=FALSE}
# Load libraries
source("jossfunc.R")
library(plyr)
library(lme4)
library(ggplot2)
library(PerformanceAnalytics)
library(dplyr)
source("jossfunc.R")


```

```{r echo=FALSE}
# Load data
dat.raw <- read.csv("C:/Users/Joss/ownCloud/Shared/DP_Derived_Data/dpLogisticDat.csv")
```
### Add additional calculated values
```{r echo=FALSE}
dat.raw$course.grade.frac <- dat.raw$course.grade/100.
dat.raw$CRT.medsplit <- trunc(dat.raw$NCRT/2)
dat.raw$final.grade.LMH <- as.integer(
  cut(dat.raw$f.tot78, quantile(dat.raw$f.tot78, probs=0:3/3), include.lowest=TRUE)
  )
dat.raw$final.grade.fix <- (dat.raw$f.tot78-2.*dat.raw$QCORRECT)/76.
dat.raw$final.gradeA.fix <- (dat.raw$f.Atot40-2.*dat.raw$QCORRECT)/38.
dat.raw$f.tot100 <- dat.raw$f.tot78/.78
```
The following is a summary of the variables present in the data file. The final 4 were caculated in this notebook. "Fix" refers to removing from the overall score on the test, the score of the specific question.
```{r}
names(dat.raw)
```

```{r echo = FALSE}
### Set categorical variables
dat.raw$ID        <- factor(dat.raw$ID)
dat.raw$QNUM      <- factor(dat.raw$QNUM)
dat.raw$TREATMENT <- factor(dat.raw$TREATMENT)
dat.raw$f.version <- factor(dat.raw$f.version)

```

```{r echo=FALSE}
### Make some data subsets

# Keep only those data points where TREATMENT was set
dat.all <- subset(dat.raw, TREATMENT==0 | TREATMENT==1)

# Remove students that didn't receive full participation credit for both EYA questions
dat.all.EYA <- subset(dat.all, EYAfinal==1)

# Look only at the 4 questions that had TREATMENT
dat.trt <- subset(dat.all.EYA, QNUM==5 | QNUM==6 | QNUM==9 | QNUM==10)
```


```{r echo = FALSE}
### Set some global variables
dodge=position_dodge(width=0.9)
```

```{r}
#dat.trt
```


# Data description


```{r echo=FALSE}
# Turn this off for now since it should really come before setting categorical vars
### Look at correlations between the variables
#chart.Correlation(select(dat.trt,TREATMENT,course.grade, f.tot100, #NCRT,QCORRECT,f.version,d.version),
#  histogram=TRUE, pch=19)
```



```{r echo=FALSE}
### Check if TREATMENT is predicted by Gender. It is not.
#m <- glmer(TREATMENT ~ Gender + (1|ID), 
#                data = dat.trt, 
#                family = binomial, control=glmerControl(optimizer="bobyqa"))
#print(summary(m))
```


### How well was each question answered?

Note that Final Exam V1 had questions 5 & 9 as treatment and V2 had questions 6 & 10 as treatment. Thus both of the questions where we are seeing a difference are from the same version. We need to confirm that these two populations are not performing differently overall. This is likely done most effectively by controlling for version, gender and other differences within the logistic regression. There are too many confounding factors to be able to see through them using bar charts.

```{r echo=FALSE}
corr.by.question <- summarySE(
  data=dat.trt, measurevar="QCORRECT", groupvars=c("TREATMENT","QNUM"),
  )

limits <- aes(ymax = QCORRECT + binomial.error, ymin = QCORRECT - binomial.error)
corr.by.question
```

```{r echo=FALSE}

ggplot(corr.by.question, aes(x=QNUM, y=QCORRECT, fill=TREATMENT)) +
  geom_bar(stat="identity", position=dodge) + 
  geom_errorbar(limits, position=dodge, width=0.25) +
  labs(x = "Question number", y = "Fraction of EYA questions correct") +
  scale_fill_discrete(labels=c("Control","Treatment")) +
  theme_bw() + 
  theme(axis.text = element_text(face = "bold")) + 
  #theme(legend.position="none")
  scale_y_continuous(limits = c(0,1)) +
  ggtitle("Error bars are binomial errors") + 
  guides(fill=guide_legend(title=NULL))
  
```


### Performance on the EYA questions by gender.
It looks like females benefit from the intervention more than males, but since the effective intervention questions were both on the same test, we need to confirm that this is not partially explained by there being a large gender difference in who wrote which test.
```{r echo=FALSE}

corr.by.gender <- summarySE(
  dat.trt, measurevar="QCORRECT", groupvars=c("TREATMENT","Gender")
  )
limits <- aes(ymax = QCORRECT + binomial.error, ymin = QCORRECT - binomial.error)

ggplot(corr.by.gender, aes(x=Gender, y=QCORRECT, fill=TREATMENT)) +
  geom_bar(stat="identity", position=dodge) + 
  geom_errorbar(limits, position=dodge, width=0.25) +
  labs(x = "Gender", y = "Fraction of EYA questions correct") +
  scale_fill_discrete(labels=c("Control","Treatment")) +
  theme_bw() + 
  theme(axis.text = element_text(face = "bold")) + 
  #theme(legend.position="none")
  scale_y_continuous(limits = c(0,1)) +
  ggtitle("Error bars are binomial errors") +
  guides(fill=guide_legend(title=NULL))
  
```
### Overall final exam grades show that the males outperformed the females
Looking at final exam performance by gender and by test version. The effect looks the opposite of what we would expect from the Test 2 intervention questions being the more effective ones. Females benefit more from the intervention. However, their score on V2 as compared to V1 is worse than the males, not better. However, the effect of the intervention on overall test grade is 0.25% (approximately 5% per question, each worth approximately 5% of the test).

```{r echo=FALSE}

final.by.gender <- summarySE(
  subset(dat.trt,QNUM==5 & f.tot100>-0.1), # Each test score appears 4 times, so this it reduces it to 1 time
  measurevar="f.tot100", groupvars=c("Gender","f.version"), calcBE=FALSE
  )
limits <- aes(ymax = f.tot100 + se, ymin = f.tot100 - se)

ggplot(final.by.gender, aes(x=Gender, y=f.tot100, fill=f.version)) +
  geom_bar(stat="identity", position=dodge) + 
  geom_errorbar(limits, position=dodge, width=0.25) +
  labs(x = "Gender", y = "Final Exam Grade (%)") +
  #scale_fill_discrete(labels=c("Control","Treatment")) +
  theme_bw() + 
  theme(axis.text = element_text(face = "bold")) + 
  #theme(legend.position="none")
  scale_y_continuous(limits = c(0,100)) +
  ggtitle("Error bars are standard error") +
  guides(fill=guide_legend(title="Test Version"))
  
```
### Effect of intervention by final exam performance group (tertile)
Since we know that females scored lower on the final exam than males, perhaps there will be a difference in the effectiveness of the intervention if we look at low, medium and high performers from the final exam. The graph shows no significant difference.

```{r echo=FALSE}

s.fLMH <- summarySE(
  dat.trt, measurevar="QCORRECT", groupvars=c("final.grade.LMH","TREATMENT")
  )
limits <- aes(ymax = QCORRECT + binomial.error, ymin = QCORRECT - binomial.error)

ggplot(s.fLMH, aes(x=final.grade.LMH, y=QCORRECT, fill=TREATMENT)) +
  geom_bar(stat="identity", position=dodge) + 
  geom_errorbar(limits, position=dodge, width=0.25) +
  labs(x = "Final Exam Score (Tertile = Low, Medium, High)", y = "Fraction of EYA questions correct") +
  scale_fill_discrete(labels=c("Control","Treatment")) +
  #theme(legend.position="none")
  #scale_x_discrete(labels=c("Low","Medium","High")) +
  scale_y_continuous(limits = c(0,1)) +
  ggtitle("Error bars are binomial errors") +
  guides(fill=guide_legend(title=NULL))

```

### Intervention effectiveness by CRT score

Spurrious correlation? The CRT scores of 2/3 are the ones where we see the difference between treatment and control.

**TODO:** Have to check this with midterm data, data from last time we did the CRT and question pair data.

```{r echo=FALSE}
s.ncrt <- summarySE(dat.trt, measurevar="QCORRECT",
                              groupvars=c("NCRT","TREATMENT"), .drop=FALSE)
limits <- aes(ymax = QCORRECT + binomial.error, ymin = QCORRECT - binomial.error)
#options(repr.plot.width=5, repr.plot.height=3)

ggplot(s.ncrt, aes(x=NCRT, y=QCORRECT, fill=TREATMENT)) + 
    geom_bar(stat="identity", position=dodge) + 
    ggtitle("Error bars are binomial errors") +
    geom_errorbar(limits, position=dodge, width=0.5)
```



### No difference in gender fractions taking each version of the test



```{r echo=FALSE}
fv1 <- length(dat.trt$Gender[dat.trt$QNUM==5 & dat.trt$Gender=="Female" & dat.trt$f.version==1])
fv2 <- length(dat.trt$Gender[dat.trt$QNUM==5 & dat.trt$Gender=="Female" & dat.trt$f.version==2])
mv1 <- length(dat.trt$Gender[dat.trt$QNUM==5 & dat.trt$Gender=="Male" & dat.trt$f.version==1])
mv2 <- length(dat.trt$Gender[dat.trt$QNUM==5 & dat.trt$Gender=="Male" & dat.trt$f.version==2])
ffv1 <- fv1/(fv1+mv1)
ffv2 <- fv2/(fv2+mv2)
fmv1 <- mv1/(fv1+mv1)
fmv2 <- mv2/(fv2+mv2)
#fisher.table(fv1, fv2, mv1, mv2)

# create a dataset
version=c(rep("V1" , 2) , rep("V2" , 2))
gender=rep(c("Female" , "Male" ), 2)
value=c(ffv1, fmv1, ffv2, fmv2)
error=c(0,sqrt((ffv1*fmv1)/(fv1+mv1)),0,sqrt((ffv2*fmv2)/(fv2+mv2)))
data=data.frame(version, gender,value, error)
limits <- aes(ymax = value+error,
              ymin = value-error)
# Stacked Percent
ggplot(data, aes(fill=gender, y=value, x=version)) + 
#    geom_bar( stat="identity", position="fill")
    geom_bar( stat="identity") +
    geom_errorbar(limits, width=0.25)

```

# Quick analyses show effect size of d=0.13

### Fisher's Exact for the four study questions combined

This is a sanity check for the logistic regressions to come. Overall we see an effect size of d=0.11, which is small, but maybe larger than one would expect from this type of intervention.

```{r echo=FALSE}
## fisher.2vector
# 2 vectors of 0s and 1s are passed
# * The first is control (top row)
# * The second is treatement (bottom row)
# Adding parenthesis around assigning a variable causes the output to be displayed
(f.result <- fisher.2vector(
  dat.trt$QCORRECT[dat.trt$TREATMENT==0],
  dat.trt$QCORRECT[dat.trt$TREATMENT==1]
)) 

```


### Simple logistic regression

```{r echo=FALSE}
m.simple <- glmer(QCORRECT ~ TREATMENT + (1|QNUM) + (1|ID), 
                data = dat.trt, 
                family = binomial, control=glmerControl(optimizer="bobyqa"))
m <- m.simple
print(summary(m))
se <- sqrt(diag(vcov(m)))
tab <- cbind(Est = fixef(m), LL = fixef(m) - 1.96 * se, UL = fixef(m) + 1.96 *se)
exp(tab)
```


```{r echo=FALSE}
# Create df to hold results
Model.vars <- c('Simple')
AIC.val <- c(round(AIC(m),1))
Odds.treatment <- c(round(exp(tab[[2]]),3))
LL <- c(round(exp(tab[[4]]),1))
UL <- c(round(exp(tab[[6]]),1))
Significant.Vars <-('None')
r.df <- data.frame(Model.vars, AIC.val, Odds.treatment, LL, UL, Significant.Vars, stringsAsFactors = FALSE)
r.df
```



### A quick summary of odds ratios so far
```{r}
odds.table <- matrix(c(
  result$estimate[[1]],
  cohens.d.from.odds.simple(result$estimate[[1]]),
  exp(tab[[2]]),
  cohens.d.from.odds.simple(exp(tab[[2]]))
),ncol=2,byrow=TRUE)
colnames(odds.table) <- c("Odds Ratio","Cohen's d")
rownames(odds.table) <- c("Fisher's Exact Test","Logistic Regression")
as.table(odds.table)


#cat("Cohen's d\n ", cohens.d.from.odds.simple(result$estimate[[1]]),"\n")
```

# Other non-interaction models

### Treatment + Gender

```{r echo=FALSE}
m.gender <- glmer(QCORRECT ~ TREATMENT + Gender + (1|QNUM) + (1|ID), 
                data = dat.trt, 
                family = binomial, control=glmerControl(optimizer="bobyqa"))
m <- m.gender
print(summary(m))
se <- sqrt(diag(vcov(m)))
tab <- cbind(Est = fixef(m), LL = fixef(m) - 1.96 * se, UL = fixef(m) + 1.96 *se)
exp(tab)
r.df <- rbind(r.df,c('Gender', round(AIC(m),1), round(exp(tab[[2]]),3), round(exp(tab[[5]]),3), 
                     round(exp(tab[[8]]),3),'***Gender'))
#r.df
```

### Treatment + overall course grade

```{r echo=FALSE}
m.course.grade <- glmer(QCORRECT ~ TREATMENT + course.grade.frac + (1|QNUM) + (1|ID), 
                data = dat.trt, 
                family = binomial, control=glmerControl(optimizer="bobyqa"))
m <- m.course.grade
print(summary(m))
se <- sqrt(diag(vcov(m)))
tab <- cbind(Est = fixef(m), LL = fixef(m) - 1.96 * se, UL = fixef(m) + 1.96 *se)
exp(tab)
r.df <- rbind(r.df,c('Course grade', round(AIC(m),1), round(exp(tab[[2]]),3), round(exp(tab[[5]]),3), 
                     round(exp(tab[[8]]),3),'***Course grade'))
```

### Treatment + Test Version

```{r echo=FALSE}
m.test.version <- glmer(QCORRECT ~ TREATMENT + f.version + (1|QNUM) + (1|ID), 
                data = dat.trt, 
                family = binomial, control=glmerControl(optimizer="bobyqa"))
m <- m.test.version
print(summary(m))
se <- sqrt(diag(vcov(m)))
tab <- cbind(Est = fixef(m), LL = fixef(m) - 1.96 * se, UL = fixef(m) + 1.96 *se)
exp(tab)
r.df <- rbind(r.df,c('Test Version', round(AIC(m),1), round(exp(tab[[2]]),3), round(exp(tab[[5]]),3), 
                     round(exp(tab[[8]]),3),'None'))
```

### TREATMENT + Final Exam Grade (corrected for intervention question scores)

```{r echo=FALSE}
m.final.exam.grade <- glmer(QCORRECT ~ TREATMENT + final.grade.fix + (1|QNUM) + (1|ID), 
                data = dat.trt, 
                family = binomial, control=glmerControl(optimizer="bobyqa"))
m <- m.final.exam.grade
print(summary(m))
se <- sqrt(diag(vcov(m)))
tab <- cbind(Est = fixef(m), LL = fixef(m) - 1.96 * se, UL = fixef(m) + 1.96 *se)
exp(tab)
r.df <- rbind(r.df,c('Final Exam Grade', round(AIC(m),1), round(exp(tab[[2]]),3), round(exp(tab[[5]]),3), 
                     round(exp(tab[[8]]),3),'***Final Exam Grade'))
```

### TREATMENT + Final Exam Grade Tertile

```{r echo=FALSE}
m.final.exam.LMH <- glmer(QCORRECT ~ TREATMENT + final.grade.LMH + (1|QNUM) + (1|ID), 
                data = dat.trt, 
                family = binomial, control=glmerControl(optimizer="bobyqa"))
m <- m.final.exam.LMH
print(summary(m))
se <- sqrt(diag(vcov(m)))
tab <- cbind(Est = fixef(m), LL = fixef(m) - 1.96 * se, UL = fixef(m) + 1.96 *se)
exp(tab)
r.df <- rbind(r.df,c('Final Exam LMH', round(AIC(m),1), round(exp(tab[[2]]),3), round(exp(tab[[5]]),3), 
                     round(exp(tab[[8]]),3),'***Final Exam LMH'))
```

### Treatment + number of CRT questions correct

```{r echo=FALSE}
m.ncrt <- glmer(QCORRECT ~ TREATMENT + NCRT + (1|QNUM) + (1|ID), 
                data = dat.trt, 
                family = binomial, control=glmerControl(optimizer="bobyqa"))
m <- m.ncrt
print(summary(m))
se <- sqrt(diag(vcov(m)))
tab <- cbind(Est = fixef(m), LL = fixef(m) - 1.96 * se, UL = fixef(m) + 1.96 *se)
exp(tab)
r.df <- rbind(r.df,c('NCRT', round(AIC(m),1), round(exp(tab[[2]]),3), round(exp(tab[[5]]),3), 
                     round(exp(tab[[8]]),3),'***NCRT'))
```

### TREATMENT + Final Exam Part A Grade (corrected for intervention question scores)

```{r echo=FALSE}
m.final.exam.partA <- glmer(QCORRECT ~ TREATMENT + final.gradeA.fix + (1|QNUM) + (1|ID), 
                data = dat.trt, 
                family = binomial, control=glmerControl(optimizer="bobyqa"))
m <- m.final.exam.partA
print(summary(m))
se <- sqrt(diag(vcov(m)))
tab <- cbind(Est = fixef(m), LL = fixef(m) - 1.96 * se, UL = fixef(m) + 1.96 *se)
exp(tab)
r.df <- rbind(r.df,c('Final Exam Part A', round(AIC(m),1), round(exp(tab[[2]]),3), round(exp(tab[[5]]),3), 
                     round(exp(tab[[8]]),3),'***Final Exam Part A'))
```

### TREATMENT + Gender + Final Exam Grade (corrected for intervention question scores)

```{r echo=FALSE}
m.gender.final.exam <- glmer(QCORRECT ~ TREATMENT + Gender + final.grade.fix + (1|QNUM) + (1|ID), 
                data = dat.trt, 
                family = binomial, control=glmerControl(optimizer="bobyqa"))
m <- m.gender.final.exam
print(summary(m))
se <- sqrt(diag(vcov(m)))
tab <- cbind(Est = fixef(m), LL = fixef(m) - 1.96 * se, UL = fixef(m) + 1.96 *se)
exp(tab)
r.df <- rbind(r.df,c('Gender + Exam Grade', round(AIC(m),1), round(exp(tab[[2]]),3), round(exp(tab[[6]]),3), 
                     round(exp(tab[[10]]),3),'***Gender, ***Exam Grade'))
```

### TREATMENT + Gender + Overall Course Grade

```{r echo=FALSE}
m.gender.course.grade <- glmer(QCORRECT ~ TREATMENT + Gender + course.grade.frac + (1|QNUM) + (1|ID), 
                data = dat.trt, 
                family = binomial, control=glmerControl(optimizer="bobyqa"))
m <- m.gender.course.grade
print(summary(m))
se <- sqrt(diag(vcov(m)))
tab <- cbind(Est = fixef(m), LL = fixef(m) - 1.96 * se, UL = fixef(m) + 1.96 *se)
exp(tab)
r.df <- rbind(r.df,c('Gender + Course Grade', round(AIC(m),1), round(exp(tab[[2]]),3), round(exp(tab[[6]]),3), 
                     round(exp(tab[[10]]),3),'***Gender, ***Course Grade'))
```

### Results

Gender is a significant predictor and will be investigated further. Final exam grade (corrected for scores on intervention questions) and course grade are both good controls, but how good may depend on the course. NCRT and Gender will be investigated further in terms of interaction terms with other variables.

The best baseline model is 

  QCORRECT ~ TREATMENT + Gender + course.grade.frac + (1|QNUM) + (1|ID)

or

  QCORRECT ~ TREATMENT + Gender + final.grade.fix + (1|QNUM) + (1|ID)
  
Adding NCRT would improve the model further, but we do not always have access to this quantity so will pursue it only if it is an investigation of CRT score, not when it is only helping to improve the model.

```{r}
r.df
```

